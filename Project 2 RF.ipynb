{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_data = pd.read_csv(r'D:\\Documents\\ITB\\S2\\WF5011 - Design of Experiment and Data Analytics\\Project-02-Data\\Project 02-Data\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features (X) and target (y)\n",
    "X = train_data.drop('price_range', axis=1)\n",
    "y = train_data['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_normalized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    max_depth=None,    # Allow trees to grow fully\n",
    "    random_state=42    # For reproducibility\n",
    ")\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')  # Weighted F1 score\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Heatmap\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize by row\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=[0, 1, 2, 3], yticklabels=[0, 1, 2, 3])\n",
    "plt.title('Confusion Matrix Heatmap (Normalized)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances[sorted_idx], align='center')\n",
    "plt.xticks(range(len(feature_importances)), feature_names[sorted_idx], rotation=90)\n",
    "plt.title('Feature Importance Plot')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the scaler for future use\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Model and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Deployment on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_data = pd.read_csv(r'D:\\Documents\\ITB\\S2\\WF5011 - Design of Experiment and Data Analytics\\Project-02-Data\\Project 02-Data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and scaler\n",
    "rf_model = joblib.load(r'D:\\Documents\\ITB\\S2\\WF5011 - Design of Experiment and Data Analytics\\random_forest_model.pkl')\n",
    "scaler = joblib.load(r'D:\\Documents\\ITB\\S2\\WF5011 - Design of Experiment and Data Analytics\\scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the test dataset\n",
    "test_features = test_data.drop('id', axis=1)  # Exclude non-feature columns like 'id'\n",
    "test_features_normalized = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = rf_model.predict(test_features_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the test dataset\n",
    "test_data['price_range'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to a CSV file\n",
    "test_data.to_csv('test_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'test_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model with manual input\n",
    "user_input = pd.DataFrame({\n",
    "    'battery_power': 1900,\n",
    "    'blue': 1,\n",
    "    'clock_speed': 0.5,\n",
    "    'dual_sim': 1,\n",
    "    'fc': 0,\n",
    "    'four_g': 1,\n",
    "    'int_memory': 55,\n",
    "    'm_dep': 0.9,\n",
    "    'mobile_wt': 171,\n",
    "    'n_cores': 1,\n",
    "    'pc': 1,\n",
    "    'px_height': 934,\n",
    "    'px_width': 1241\n",
    "    'ram': 3917,\n",
    "    'sc_h': 15,\n",
    "    'sc_w': 5,\n",
    "    'talk_time': 18,\n",
    "    'three_g': 1,\n",
    "    'touch_screen': 0,\n",
    "    'wifi': 1\n",
    "    })\n",
    "\n",
    "# Normalize the features using the saved scaler\n",
    "user_input_normalized = scaler.transform(user_input)\n",
    "\n",
    "# Predict the price range using the saved model\n",
    "prediction = rf_model.predict(user_input_normalized)\n",
    "\n",
    "# Output the predicted price range\n",
    "print(f\"\\nPredicted Price Range: {prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LBC24-GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
